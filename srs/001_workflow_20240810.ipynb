{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de librerias basicas tablas y matrices\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Funciones auxiliares sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold #Split y cross Validation\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, balanced_accuracy_score #Metricas\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Visualizacióon\n",
    "from plotly import express as px\n",
    "\n",
    "#Plot de matriz de confusion normalizada en actuals\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "#Optimizacion de hiperparametros\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "#Guardado de objetos en archivos joblib\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths para acceso archivos\n",
    "#Este notebook asume la siguiente estructura de carpetas a partir de la ubicacion de base_dir \n",
    "#(dos niveles arriba de la carpeta donde se ejecuta el notebook). \n",
    "# /UA_MDM_LDI_II/\n",
    "# /UA_MDM_LDI_II/input\n",
    "# /UA_MDM_LDI_II/input/petfinder-adoption-prediction/            <- Aca deben ir todos los archivos de datos de la competencia \n",
    "# /UA_MDM_LDI_II/tutoriales/                       <- Aca deben poner los notebooks y scripts que les compartimos\n",
    "# /UA_MDM_LDI_II/work/                             <- Resultados de notebooks iran dentro de esta carpeta en subcarpetas\n",
    "# /UA_MDM_LDI_II/work/models/                     <- Modelos entrenados en archivos joblibs\n",
    "# /UA_MDM_LDI_II/work/optuna_temp_artifacts/      <- Archivos que queremos dejar como artefacto de un trial de optuna (optuna los copiara a la carpeta de abajo)\n",
    "# /UA_MDM_LDI_II/work/optuna_artifacts/           <- Archivos con artefactos que sibimos a optuna\n",
    "\n",
    "#Subimos dos niveles para quedar en la carpeta que contiene input y UA_MDM_LDI_II\n",
    "BASE_DIR = '../'\n",
    "\n",
    "#Datos de entrenamiento \n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_TEST = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/test/test.csv\")\n",
    "\n",
    "#Salida de modelos entrenados\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"work/models\")\n",
    "\n",
    "#Artefactos a subir a optuna\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "\n",
    "#Artefactos que optuna gestiona\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "\n",
    "SEED = 42 #Semilla de procesos aleatorios (para poder replicar exactamente al volver a correr un modelo)\n",
    "TEST_SIZE = 0.2 #Facción para train/test= split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_train = pd.read_csv(PATH_TO_TRAIN)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3972, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_test = pd.read_csv(PATH_TO_TEST)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "\n",
    "| Variable       | Type         | Description                                                                           |\n",
    "|----------------|--------------|---------------------------------------------------------------------------------------|\n",
    "| `PetID`        | Categorical  | ID (Should be dropped)                                                                |\n",
    "| `AdoptionSpeed`| Categorical  | Target variable                                                                       |\n",
    "| `Type`         | Categorical  | 1 = Cat, 2 = Dog                                                                      |\n",
    "| `Name`         | Categorical  | Name of pet                                                                           |\n",
    "| `Breed1`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Breed2`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Gender`       | Categorical  | 1 = Male, 2 = Female, 3 = Mixed (used for groups)                                     |\n",
    "| `Color1`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color2`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color3`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `MaturitySize` | Categorical  | 1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified                  |\n",
    "| `FurLength`    | Categorical  | 1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified                                    |\n",
    "| `Vaccinated`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Dewormed`     | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Sterilized`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Health`       | Categorical  | 1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified                  |\n",
    "| `State`        | Categorical  | See StateLabels dictionary                                                            |\n",
    "| `RescuerID`    | Categorical  | ID                                                                                    |\n",
    "| `Description`  | Text         | Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese. |\n",
    "\n",
    "### Quantitative Variables\n",
    "\n",
    "| Variable   | Type             |Description                                           |\n",
    "|------------|------------------|------------------------------------------------------|\n",
    "| `Age`      |  Numerical       |Age of pet when listed, in months                     |\n",
    "| `Quantity` |  Numerical       |Number of pets represented in profile                 |\n",
    "| `Fee`      |  Numerical       |Adoption fee (0 = Free)                               |\n",
    "| `VideoAmt` |  Numerical       |Total uploaded videos for this pet                    |\n",
    "| `PhotoAmt` |  Numerical       |Total uploaded photos for this pet                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_fe(dataset):\n",
    "    # Name\n",
    "    # Feature to know if the pet has a name\n",
    "    dataset['Name'] = np.where(dataset['Name'].str.lower().str.contains('name|puppies|kitten|puppy|unknown'), np.nan, dataset['Name'])\n",
    "    dataset['HasName'] = dataset['Name'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "    \n",
    "    # Breed\n",
    "    # Unify values in Breed1\n",
    "    dataset['Breed1'] = np.where((dataset['Breed1']==0) & (dataset['Breed2']!=0), dataset['Breed2'], dataset['Breed1'])\n",
    "    dataset['Breed2'] = np.where((dataset['Breed1']==dataset['Breed2']), 0, dataset['Breed2'])\n",
    "    \n",
    "    # Merge Breed1 and Breed2\n",
    "    dataset['FullBreed'] = dataset['Breed1'].astype(str) + '_' + dataset['Breed2'].astype(str) \n",
    "    # Pure breed\n",
    "    dataset['PureBreed'] = np.where((dataset['Breed2'] == 0) & (~dataset['Breed1'].isin([307, 266, 265, 264])), 1, 0)\n",
    "    \n",
    "    # Color\n",
    "    # Merge Color1, Color2 and Color3\n",
    "    dataset['Color'] = dataset['Color1'].astype(str) + '_' + dataset['Color2'].astype(str) + '_' + dataset['Color3'].astype(str)\n",
    "    # Monochromatic\n",
    "    dataset['Monochromatic'] = np.where((dataset['Color2'] == 0) & (dataset['Color3'] == 0), 1, 0)\n",
    "    \n",
    "    # Health\n",
    "    # Merge Vaccinated, Dewormed and Sterilized to know if the pet is up to date with routine stuff\n",
    "    dataset['Va_De_St'] = dataset['Vaccinated'].astype(str) + '_' + dataset['Dewormed'].astype(str) + '_' + dataset['Sterilized'].astype(str)\n",
    "\n",
    "    # Code to add a min age for sterilization.... But EDA shows that they do it anyway\n",
    "    #df['CanBeSter'] = np.where((df['Age'] > 9) & (df['Type'] == 1) | (df['Age'] > 6) & (df['Type'] == 2), 1, 0)\n",
    "    \n",
    "    # Fee\n",
    "    # Create fee bins using log transformation\n",
    "    dataset['Fee_bins'] = pd.cut(np.log1p(dataset.Fee), 5, labels=['Fee_{}'.format(e) for e in range(5)])\n",
    "\n",
    "    #RescuerID\n",
    "    rescuer_count = dataset.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "    rescuer_count.columns = ['RescuerID', 'Rescuer_count']\n",
    "    dataset = dataset.merge(rescuer_count, how='left', on='RescuerID')\n",
    "\n",
    "    # Age\n",
    "    dataset['RelAge'] = np.where(dataset['Type'] == 1, dataset['Age']/144, dataset['Age']/180) # Vida media de un gato 12 años, de un perro 15\n",
    "\n",
    "    # Multimedia\n",
    "    dataset['Total_photo_video'] = dataset['PhotoAmt'] + dataset['VideoAmt']\n",
    "\n",
    "    # State\n",
    "\n",
    "    \n",
    "    # Return the augmented dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = apply_fe(df_train.copy())\n",
    "df_test = apply_fe(df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean adoption speed per state and add that value to train and test datasets\n",
    "state_mean = df_train.groupby('State')['AdoptionSpeed'].mean().reset_index()\n",
    "state_mean.columns = ['State', 'AdoptionSpeed_mean']\n",
    "df_train = df_train.merge(state_mean, how='left', on='State')\n",
    "df_test = df_test.merge(state_mean, how='left', on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
       "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'AdoptionSpeed',\n",
       "       'HasName', 'FullBreed', 'PureBreed', 'Color', 'Monochromatic',\n",
       "       'Va_De_St', 'Fee_bins', 'Rescuer_count', 'RelAge', 'Total_photo_video',\n",
       "       'AdoptionSpeed_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armo listas con features de texto y numericas\n",
    "char_feats = ['Type', 'Name', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized', 'Health',  'Fee', 'State', 'RescuerID',       \n",
    "       'HasName', 'FullBreed', 'PureBreed', 'Color', 'Monochromatic',\n",
    "       'Va_De_St', 'Fee_bins',   \n",
    "       ]\n",
    "numeric_feats = ['Age','Quantity','PhotoAmt','VideoAmt','Total_photo_video','RelAge','Rescuer_count','AdoptionSpeed_mean']\n",
    "\n",
    "fe_drop = ['Description', 'PetID',  'AdoptionSpeed',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AdoptionSpeed'\n",
    "fe_drop = ['PetID', 'Description', 'AdoptionSpeed']\n",
    "char_feats = list(set(char_feats) - set(fe_drop))\n",
    "y = df_train[target]\n",
    "X = df_train.drop(fe_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=SEED, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 24)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns.to_list()), len(char_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(min_frequency= 30, handle_unknown= 'use_encoded_value', unknown_value= -1), char_feats)],\n",
    "        remainder= 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = preprocessor.fit_transform(X_train)\n",
    "X_test2 = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                     int64\n",
       "Name                    object\n",
       "Age                      int64\n",
       "Breed1                   int64\n",
       "Breed2                   int64\n",
       "Gender                   int64\n",
       "Color1                   int64\n",
       "Color2                   int64\n",
       "Color3                   int64\n",
       "MaturitySize             int64\n",
       "FurLength                int64\n",
       "Vaccinated               int64\n",
       "Dewormed                 int64\n",
       "Sterilized               int64\n",
       "Health                   int64\n",
       "Quantity                 int64\n",
       "Fee                      int64\n",
       "State                    int64\n",
       "RescuerID               object\n",
       "VideoAmt                 int64\n",
       "PhotoAmt               float64\n",
       "HasName                  int64\n",
       "FullBreed               object\n",
       "PureBreed                int64\n",
       "Color                   object\n",
       "Monochromatic            int64\n",
       "Va_De_St                object\n",
       "Fee_bins              category\n",
       "Rescuer_count            int64\n",
       "RelAge                 float64\n",
       "Total_photo_video      float64\n",
       "AdoptionSpeed_mean     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 630\n",
      "[LightGBM] [Info] Number of data points in the train set: 11994, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -3.599148\n",
      "[LightGBM] [Info] Start training from score -1.579379\n",
      "[LightGBM] [Info] Start training from score -1.311924\n",
      "[LightGBM] [Info] Start training from score -1.526206\n",
      "[LightGBM] [Info] Start training from score -1.273359\n"
     ]
    }
   ],
   "source": [
    "#Entreno un modelo inicial sin modificar hiperparametros. Solamente especifico el numero de clases y el tipo de modelo como clasificacoión\n",
    "lgb_params = params = {\n",
    "                        'objective': 'multiclass',\n",
    "                        'num_class': 5\n",
    "                        }\n",
    "\n",
    "\n",
    "#genero el objeto Dataset que debo pasarle a lightgbm para que entrene\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train2,\n",
    "                                label=y_train)\n",
    "\n",
    "#entreno el modelo con los parametros por defecto\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3537168666398812"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgb_model.predict(X_test2).argmax(axis=1)\n",
    "\n",
    "#Calculo el Kappa\n",
    "cohen_kappa_score(y_test,y_pred, weights = 'quadratic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
