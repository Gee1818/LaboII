{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import de librerias basicas tablas y matrices\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Funciones auxiliares sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold #Split y cross Validation\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, balanced_accuracy_score #Metricas\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "\n",
    "\n",
    "#Visualizacióon\n",
    "from plotly import express as px\n",
    "\n",
    "#Plot de matriz de confusion normalizada en actuals\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "#Optimizacion de hiperparametros\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "#Guardado de objetos en archivos joblib\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths para acceso archivos\n",
    "#Este notebook asume la siguiente estructura de carpetas a partir de la ubicacion de base_dir \n",
    "#(dos niveles arriba de la carpeta donde se ejecuta el notebook). \n",
    "# /UA_MDM_LDI_II/\n",
    "# /UA_MDM_LDI_II/input\n",
    "# /UA_MDM_LDI_II/input/petfinder-adoption-prediction/            <- Aca deben ir todos los archivos de datos de la competencia \n",
    "# /UA_MDM_LDI_II/tutoriales/                       <- Aca deben poner los notebooks y scripts que les compartimos\n",
    "# /UA_MDM_LDI_II/work/                             <- Resultados de notebooks iran dentro de esta carpeta en subcarpetas\n",
    "# /UA_MDM_LDI_II/work/models/                     <- Modelos entrenados en archivos joblibs\n",
    "# /UA_MDM_LDI_II/work/optuna_temp_artifacts/      <- Archivos que queremos dejar como artefacto de un trial de optuna (optuna los copiara a la carpeta de abajo)\n",
    "# /UA_MDM_LDI_II/work/optuna_artifacts/           <- Archivos con artefactos que sibimos a optuna\n",
    "\n",
    "#Subimos dos niveles para quedar en la carpeta que contiene input y UA_MDM_LDI_II\n",
    "BASE_DIR = '../'\n",
    "\n",
    "#Datos de entrenamiento \n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_TEST = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/test/test.csv\")\n",
    "\n",
    "#Salida de modelos entrenados\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"work/models\")\n",
    "\n",
    "#Artefactos a subir a optuna\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "\n",
    "#Artefactos que optuna gestiona\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "\n",
    "SEED = 42 #Semilla de procesos aleatorios (para poder replicar exactamente al volver a correr un modelo)\n",
    "TEST_SIZE = 0.2 #Facción para train/test= split\n",
    "\n",
    "# Config for pandas output from pipelines\n",
    "set_config(transform_output = \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_train = pd.read_csv(PATH_TO_TRAIN)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3972, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_test = pd.read_csv(PATH_TO_TEST)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otros archivos\n",
    "\n",
    "# States diccionary\n",
    "df_state_labels = pd.read_csv(os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/StateLabels.csv\"))\n",
    "df_state_labels['State_Pop'] = [\n",
    "    3794,\n",
    "    2194,\n",
    "    1929,\n",
    "    1746,\n",
    "    100,\n",
    "    937,\n",
    "    1129,\n",
    "    1685,\n",
    "    2509,\n",
    "    255,\n",
    "    1774,\n",
    "    3833,\n",
    "    2822,\n",
    "    6555,\n",
    "    1275\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "\n",
    "| Variable       | Type         | Description                                                                           |\n",
    "|----------------|--------------|---------------------------------------------------------------------------------------|\n",
    "| `PetID`        | Categorical  | ID (Should be dropped)                                                                |\n",
    "| `AdoptionSpeed`| Categorical  | Target variable                                                                       |\n",
    "| `Type`         | Categorical  | 1 = Cat, 2 = Dog                                                                      |\n",
    "| `Name`         | Categorical  | Name of pet                                                                           |\n",
    "| `Breed1`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Breed2`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Gender`       | Categorical  | 1 = Male, 2 = Female, 3 = Mixed (used for groups)                                     |\n",
    "| `Color1`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color2`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color3`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `MaturitySize` | Categorical  | 1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified                  |\n",
    "| `FurLength`    | Categorical  | 1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified                                    |\n",
    "| `Vaccinated`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Dewormed`     | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Sterilized`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Health`       | Categorical  | 1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified                  |\n",
    "| `State`        | Categorical  | See StateLabels dictionary                                                            |\n",
    "| `RescuerID`    | Categorical  | ID                                                                                    |\n",
    "| `Description`  | Text         | Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese. |\n",
    "\n",
    "### Quantitative Variables\n",
    "\n",
    "| Variable   | Type             |Description                                           |\n",
    "|------------|------------------|------------------------------------------------------|\n",
    "| `Age`      |  Numerical       |Age of pet when listed, in months                     |\n",
    "| `Quantity` |  Numerical       |Number of pets represented in profile                 |\n",
    "| `Fee`      |  Numerical       |Adoption fee (0 = Free)                               |\n",
    "| `VideoAmt` |  Numerical       |Total uploaded videos for this pet                    |\n",
    "| `PhotoAmt` |  Numerical       |Total uploaded photos for this pet                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ge/MCD/LaboII/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_fe(dataset):\n",
    "    # Name\n",
    "    # Feature to know if the pet has a name\n",
    "    unknown_names = 'name|puppies|kitten|puppy|unknown'\n",
    "    dataset['Name'] = np.where(dataset['Name'].str.lower().str.contains(unknown_names), np.nan, dataset['Name'])\n",
    "    dataset['Name'] = np.where(dataset['Name'].str.len() < 3, np.nan, dataset['Name'])\n",
    "    dataset['HasName'] = dataset['Name'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "    \n",
    "    # Breed\n",
    "    # Unify values in Breed1\n",
    "    dataset['Breed1'] = np.where((dataset['Breed1']==0) & (dataset['Breed2']!=0), dataset['Breed2'], dataset['Breed1'])\n",
    "    dataset['Breed2'] = np.where((dataset['Breed1']==dataset['Breed2']), 0, dataset['Breed2'])\n",
    "    \n",
    "    # Merge Breed1 and Breed2\n",
    "    dataset['FullBreed'] = dataset['Breed1'].astype(str) + '_' + dataset['Breed2'].astype(str) \n",
    "    # Pure breed\n",
    "    dataset['PureBreed'] = np.where((dataset['Breed2'] == 0) & (~dataset['Breed1'].isin([307, 266, 265, 264])), 1, 0)\n",
    "    \n",
    "    # Color\n",
    "    # Merge Color1, Color2 and Color3\n",
    "    dataset['Color'] = dataset['Color1'].astype(str) + '_' + dataset['Color2'].astype(str) + '_' + dataset['Color3'].astype(str)\n",
    "    # Monochromatic\n",
    "    dataset['Monochromatic'] = np.where((dataset['Color2'] == 0) & (dataset['Color3'] == 0), 1, 0)\n",
    "    \n",
    "    # Health\n",
    "    # Merge Vaccinated, Dewormed and Sterilized to know if the pet is up to date with routine stuff\n",
    "    dataset['Va_De_St'] = dataset['Vaccinated'].astype(str) + '_' + dataset['Dewormed'].astype(str) + '_' + dataset['Sterilized'].astype(str)\n",
    "\n",
    "    # Code to add a min age for sterilization.... But EDA shows that they do it anyway\n",
    "    #df['CanBeSter'] = np.where((df['Age'] > 9) & (df['Type'] == 1) | (df['Age'] > 6) & (df['Type'] == 2), 1, 0)\n",
    "    \n",
    "    # Fee\n",
    "    # Create fee bins using log transformation\n",
    "    dataset['Fee_bins'] = pd.cut(np.log1p(dataset.Fee), 5, labels=['Fee_{}'.format(e) for e in range(5)])\n",
    "\n",
    "    #RescuerID\n",
    "    rescuer_count = dataset.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "    rescuer_count.columns = ['RescuerID', 'Rescuer_count']\n",
    "    dataset = dataset.merge(rescuer_count, how='left', on='RescuerID')\n",
    "\n",
    "    # Age\n",
    "    dataset['RelAge'] = np.where(dataset['Type'] == 1, dataset['Age']/144, dataset['Age']/180) # Vida media de un gato 12 años, de un perro 15\n",
    "\n",
    "    # Multimedia\n",
    "    dataset['Total_photo_video'] = dataset['PhotoAmt'] + dataset['VideoAmt']\n",
    "\n",
    "    # Si tiene todo lo del veterinatrio en orden\n",
    "    dataset['VetInOrder'] = np.where((dataset['Vaccinated'] == 1) & (dataset['Dewormed'] == 1) & (dataset['Sterilized'] == 1) & (dataset['Health'] == 1), 1, 0)\n",
    "\n",
    "    # Si le falta info sobre lo relacionado a veterinario\n",
    "    dataset['NoVet'] = np.where((dataset['Vaccinated'] == 3) | (dataset['Dewormed'] == 3) | (dataset['Sterilized'] == 3) | (dataset['Health'] == 3), 1, 0)\n",
    "\n",
    "    # Longitud de la descripcion\n",
    "    dataset['LenDesc'] = dataset['Description'].apply(lambda x: len(str(x)))\n",
    "\n",
    "    # variable \"age_categ\" para categorizar age (identica para perros y gatos, sin problemas según fuentes)\n",
    "    age_categ_cuts = [\n",
    "        (dataset['Age'].le(1*12)),\n",
    "        (dataset['Age'].gt(1*12) & dataset['Age'].le(3*12)),\n",
    "        (dataset['Age'].gt(3*12) & dataset['Age'].le(9*12)),\n",
    "        (dataset['Age'].gt(9*12))   \n",
    "    ]\n",
    "    age_categ_values = [\"baby\",\"young\",\"adult\",\"old\"]\n",
    "    dataset['Age_categ'] = np.select(age_categ_cuts, age_categ_values)\n",
    "\n",
    "    # variable \"individual\" para saber si es un animal solo o un grupo\n",
    "    dataset['Individual'] = np.where((dataset['Quantity'].gt(1)),1,0)\n",
    "\n",
    "    #variable \"free\" para saber si hay que pagar o no por adoptar\n",
    "    dataset['Free'] = np.where((dataset['Fee'].gt(0)),1,0)\n",
    "\n",
    "    # agrego state label y state population\n",
    "    dataset = pd.merge(dataset, df_state_labels, how = \"left\", left_on='State',right_on='StateID')\n",
    "\n",
    "    # Return the augmented dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = apply_fe(df_train.copy())\n",
    "df_test = apply_fe(df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['AdoptionSpeed']\n",
    "X = df_train.drop(columns=['AdoptionSpeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=SEED, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean adoption speed per state and add that value to train and test datasets\n",
    "state_mean = pd.concat([X_train['State'], y_train], axis=1).groupby('State')['AdoptionSpeed'].mean().reset_index()\n",
    "state_mean.columns = ['State', 'AdoptionSpeed_mean']\n",
    "X_train = X_train.merge(state_mean, how='left', on='State')\n",
    "X_val = X_val.merge(state_mean, how='left', on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
       "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'HasName', 'FullBreed',\n",
       "       'PureBreed', 'Color', 'Monochromatic', 'Va_De_St', 'Fee_bins',\n",
       "       'Rescuer_count', 'RelAge', 'Total_photo_video', 'VetInOrder', 'NoVet',\n",
       "       'LenDesc', 'Age_categ', 'Individual', 'Free', 'StateID', 'StateName',\n",
       "       'State_Pop', 'AdoptionSpeed_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
       "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'HasName', 'FullBreed',\n",
       "       'PureBreed', 'Color', 'Monochromatic', 'Va_De_St', 'Fee_bins',\n",
       "       'Rescuer_count', 'RelAge', 'Total_photo_video', 'VetInOrder', 'NoVet',\n",
       "       'LenDesc', 'Age_categ', 'Individual', 'Free', 'StateID', 'StateName',\n",
       "       'State_Pop', 'AdoptionSpeed_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armo listas con features de texto y numericas\n",
    "char_feats = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized','Health', 'State', 'RescuerID',\n",
    "       'Description', 'HasName', 'FullBreed',\n",
    "       'PureBreed', 'Color', 'Monochromatic', 'Va_De_St', 'Fee_bins', 'VetInOrder', 'NoVet','VideoAmt','PhotoAmt','Total_photo_video', 'Name',\n",
    "       'Age_categ', 'Individual', 'Free', 'StateName'\n",
    "       ]\n",
    "#\n",
    "numeric_feats = ['Age', 'Quantity', 'Fee', 'RelAge',\n",
    "       'Rescuer_count', 'LenDesc', 'AdoptionSpeed_mean', ]\n",
    "\n",
    "fe_drop = ['PetID','Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para revisar que tenemos todas las columnas en las variables\n",
    "X_train.shape[1]-len(fe_drop)-len(char_feats)-len(numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_id = X_train['PetID']\n",
    "X_train = X_train[char_feats + numeric_feats]\n",
    "\n",
    "X_val_id = X_val['PetID']\n",
    "\n",
    "#X_val_id.to_csv(os.path.join(BASE_DIR, \"input/val_id.csv'), index=False)\n",
    "X_val = X_val[char_feats + numeric_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(min_frequency= 30, handle_unknown= 'use_encoded_value', unknown_value= -1), char_feats)],\n",
    "        remainder= 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 328, number of negative: 11666\n",
      "[LightGBM] [Info] Number of positive: 2472, number of negative: 9522\n",
      "[LightGBM] [Info] Number of positive: 3230, number of negative: 8764\n",
      "[LightGBM] [Info] Number of positive: 2607, number of negative: 9387\n",
      "[LightGBM] [Info] Number of positive: 3357, number of negative: 8637\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 907\n",
      "[LightGBM] [Info] Number of data points in the train set: 11994, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027347 -> initscore=-3.571420\n",
      "[LightGBM] [Info] Start training from score -3.571420\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206103 -> initscore=-1.348577\n",
      "[LightGBM] [Info] Start training from score -1.348577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.269301 -> initscore=-0.998170\n",
      "[LightGBM] [Info] Start training from score -0.998170\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217359 -> initscore=-1.281126\n",
      "[LightGBM] [Info] Start training from score -1.281126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.279890 -> initscore=-0.945008\n",
      "[LightGBM] [Info] Start training from score -0.945008\n"
     ]
    }
   ],
   "source": [
    "#Entreno un modelo inicial sin modificar hiperparametros. Solamente especifico el numero de clases y el tipo de modelo como clasificacoión\n",
    "lgb_params = params = {\n",
    "                        'objective': 'multiclassova',\n",
    "                        'num_class': 5,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'n_estimators': 1000,\n",
    "                        'device': 'cpu'\n",
    "                        }\n",
    "\n",
    "\n",
    "#genero el objeto Dataset que debo pasarle a lightgbm para que entrene\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "#entreno el modelo con los parametros por defecto\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3483360166031384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgb_model.predict(X_val).argmax(axis=1)\n",
    "\n",
    "#Calculo el Kappa\n",
    "cohen_kappa_score(y_val,y_pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>remainder__LenDesc</td>\n",
       "      <td>117271.395867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>remainder__Rescuer_count</td>\n",
       "      <td>115353.877126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>remainder__RelAge</td>\n",
       "      <td>85741.076378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat__Breed1</td>\n",
       "      <td>50646.854816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cat__PhotoAmt</td>\n",
       "      <td>47276.312706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cat__Color</td>\n",
       "      <td>42568.556228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>remainder__Age</td>\n",
       "      <td>38724.610719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cat__FullBreed</td>\n",
       "      <td>29661.240513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cat__Va_De_St</td>\n",
       "      <td>27408.956937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>remainder__AdoptionSpeed_mean</td>\n",
       "      <td>24945.529847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature         weight\n",
       "38             remainder__LenDesc  117271.395867\n",
       "37       remainder__Rescuer_count  115353.877126\n",
       "36              remainder__RelAge   85741.076378\n",
       "1                     cat__Breed1   50646.854816\n",
       "26                  cat__PhotoAmt   47276.312706\n",
       "19                     cat__Color   42568.556228\n",
       "33                 remainder__Age   38724.610719\n",
       "17                 cat__FullBreed   29661.240513\n",
       "21                  cat__Va_De_St   27408.956937\n",
       "39  remainder__AdoptionSpeed_mean   24945.529847"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'feature': preprocessor.get_feature_names_out(), 'weight': lgb_model.feature_importance(importance_type='gain')})\n",
    "feature_importance.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una metrica para que lightGBM haga la evaluación y pueda hacer early_stopping en el cross validation\n",
    "def lgb_custom_metric_kappa(dy_pred, dy_true):\n",
    "    metric_name = 'kappa'\n",
    "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
    "    is_higher_better = True\n",
    "    return(metric_name, value, is_higher_better)\n",
    "\n",
    "#Funcion objetivo a optimizar. En este caso vamos a hacer 5fold cv sobre el conjunto de train. \n",
    "# El score de CV es el objetivo a optimizar. Ademas vamos a usar los 5 modelos del CV para estimar el conjunto de test,\n",
    "# registraremos en optuna las predicciones, matriz de confusion y el score en test.\n",
    "# CV Score -> Se usa para determinar el rendimiento de los hiperparametros con precision \n",
    "# Test Score -> Nos permite testear que esta todo OK, no use (ni debo usar) esos datos para nada en el entrenamiento \n",
    "# o la optimizacion de hiperparametros\n",
    "\n",
    "def cv_es_lgb_objective(trial):\n",
    "\n",
    "    #PArametros para LightGBM\n",
    "    lgb_params = {      \n",
    "                        #PArametros fijos\n",
    "                        'objective': 'multiclassova',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'seed': SEED,\n",
    "                        \n",
    "                        #Hiperparametros a optimizar utilizando suggest_float o suggest_int segun el tipo de dato\n",
    "                        #Se indica el nombre del parametro, valor minimo, valor maximo \n",
    "                        #en elgunos casos el parametro log=True para parametros que requieren buscar en esa escala\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-7, 1e-4, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-5, 0.1, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 100, 256),\n",
    "                        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.01),\n",
    "                        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 15, 70),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.9),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 3),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 20, 60),\n",
    "                        'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
    "                        'min_split_gain': trial.suggest_float('min_split_gain', 5, 8),\n",
    "                        \"max_bin\": trial.suggest_int('max_bin', 300, 500),\n",
    "                        } \n",
    "\n",
    "    #Voy a generar estimaciones de los 5 modelos del CV sobre los datos test y los acumulo en la matriz scores_ensemble\n",
    "    scores_ensemble = np.zeros((len(y_val),len(y_train.unique())))\n",
    "\n",
    "    #Score del 5 fold CV inicializado en 0\n",
    "    score_folds = 0\n",
    "\n",
    "    #Numero de splits del CV\n",
    "    n_splits = 5\n",
    "\n",
    "    #Objeto para hacer el split estratificado de CV\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        \n",
    "        #Dataset in fold (donde entreno) \n",
    "        lgb_if_dataset = lgb.Dataset(data=X_train.iloc[if_index],\n",
    "                                        label=y_train.iloc[if_index],\n",
    "                                        free_raw_data=False)\n",
    "        \n",
    "        #Dataset Out of fold (donde mido la performance del CV)\n",
    "        lgb_oof_dataset = lgb.Dataset(data=X_train.iloc[oof_index],\n",
    "                                        label=y_train.iloc[oof_index],\n",
    "                                        free_raw_data=False)\n",
    "\n",
    "        #Entreno el modelo\n",
    "        lgb_model = lgb.train(lgb_params,\n",
    "                                lgb_if_dataset,\n",
    "                                valid_sets=lgb_oof_dataset,\n",
    "                                feval = lgb_custom_metric_kappa\n",
    "                                )\n",
    "        \n",
    "        #Acumulo los scores (probabilidades) de cada clase para cada uno de los modelos que determino en los folds\n",
    "        #Se predice el 20% de los datos que separe para tes y no uso para entrenar en ningun fold\n",
    "        scores_ensemble = scores_ensemble + lgb_model.predict(X_val)\n",
    "        \n",
    "        #Score del fold (registros de dataset train que en este fold quedan out of fold)\n",
    "        score_folds = score_folds + cohen_kappa_score(y_train.iloc[oof_index], \n",
    "                                                            lgb_model.predict(X_train.iloc[oof_index]).argmax(axis=1),weights = 'quadratic')/n_splits\n",
    "\n",
    "\n",
    "    #Guardo prediccion del trial sobre el conjunto de test\n",
    "    # Genero nombre de archivo\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    # Copia del dataset para guardar la prediccion\n",
    "    predicted_df = pd.DataFrame(X_val,y_val).copy()\n",
    "    # Genero columna pred con predicciones sumadas de los 5 folds\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    # Grabo dataframe en temp_artifacts\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    # Indico a optuna que asocie el archivo generado al trial\n",
    "    #upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "    #Grabo natriz de confusion\n",
    "    #Nombre de archivo\n",
    "    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "    #Grabo archivo\n",
    "    plot_confusion_matrix(y_val,scores_ensemble.argmax(axis=1)).write_image(cm_filename)\n",
    "    #Asocio al trial\n",
    "    #upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "    #Determino score en conjunto de test y asocio como metrica adicional en optuna\n",
    "    test_score = cohen_kappa_score(y_val,scores_ensemble.argmax(axis=1),weights = 'quadratic')\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    #Devuelvo score del 5fold cv a optuna para que optimice en base a eso\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.361781:  50%|█████     | 100/200 [1:42:14<1:42:14, 61.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-10-13 16:04:03,811] Trial 100 failed with parameters: {'lambda_l1': 1.2578274755080858e-05, 'lambda_l2': 0.0010561116496413025, 'num_leaves': 237, 'learning_rate': 0.008602492972600115, 'min_data_in_leaf': 25, 'feature_fraction': 0.6086483948711785, 'bagging_fraction': 0.7303466623417876, 'bagging_freq': 2, 'min_child_samples': 20, 'n_estimators': 1219, 'min_split_gain': 5.0501879969712204, 'max_bin': 420} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1936/3634229298.py\", line 67, in cv_es_lgb_objective\n",
      "    lgb_model = lgb.train(lgb_params,\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/engine.py\", line 368, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/basic.py\", line 4419, in eval_valid\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/basic.py\", line 5180, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1936/3634229298.py\", line 4, in lgb_custom_metric_kappa\n",
      "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 713, in cohen_kappa_score\n",
      "    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ge/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 376, in confusion_matrix\n",
      "    y_pred = np.array([label_to_ind.get(x, n_labels + 1) for x in y_pred])\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-13 16:04:03,858] Trial 100 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_optuna:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_es_lgb_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[22], line 67\u001b[0m, in \u001b[0;36mcv_es_lgb_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     62\u001b[0m lgb_oof_dataset \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39miloc[oof_index],\n\u001b[1;32m     63\u001b[0m                                 label\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39miloc[oof_index],\n\u001b[1;32m     64\u001b[0m                                 free_raw_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#Entreno el modelo\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlgb_if_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgb_oof_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlgb_custom_metric_kappa\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#Acumulo los scores (probabilidades) de cada clase para cada uno de los modelos que determino en los folds\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#Se predice el 20% de los datos que separe para tes y no uso para entrenar en ningun fold\u001b[39;00m\n\u001b[1;32m     75\u001b[0m scores_ensemble \u001b[38;5;241m=\u001b[39m scores_ensemble \u001b[38;5;241m+\u001b[39m lgb_model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/engine.py:368\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    367\u001b[0m         evaluation_result_list\u001b[38;5;241m.\u001b[39mextend(booster\u001b[38;5;241m.\u001b[39meval_train(feval))\n\u001b[0;32m--> 368\u001b[0m     evaluation_result_list\u001b[38;5;241m.\u001b[39mextend(\u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_after_iter:\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/basic.py:4419\u001b[0m, in \u001b[0;36mBooster.eval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   4384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_valid\u001b[39m(\n\u001b[1;32m   4385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4386\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[1;32m   4388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[1;32m   4389\u001b[0m \n\u001b[1;32m   4390\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4414\u001b[0m \u001b[38;5;124;03m        List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[1;32m   4415\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   4417\u001b[0m         item\n\u001b[1;32m   4418\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)\n\u001b[0;32m-> 4419\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_valid_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4420\u001b[0m     ]\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/lightgbm/basic.py:5180\u001b[0m, in \u001b[0;36mBooster.__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5179\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 5180\u001b[0m feval_ret \u001b[38;5;241m=\u001b[39m \u001b[43meval_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feval_ret, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   5182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, val, is_higher_better \u001b[38;5;129;01min\u001b[39;00m feval_ret:\n",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m, in \u001b[0;36mlgb_custom_metric_kappa\u001b[0;34m(dy_pred, dy_true)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlgb_custom_metric_kappa\u001b[39m(dy_pred, dy_true):\n\u001b[1;32m      3\u001b[0m     metric_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkappa\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mcohen_kappa_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdy_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdy_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquadratic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     is_higher_better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(metric_name, value, is_higher_better)\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:713\u001b[0m, in \u001b[0;36mcohen_kappa_score\u001b[0;34m(y1, y2, labels, weights, sample_weight)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    640\u001b[0m     {\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m )\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcohen_kappa_score\u001b[39m(y1, y2, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    650\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m    This function computes Cohen's kappa [1]_, a score that expresses the level\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m    np.float64(0.6875)\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m     confusion \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m confusion\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    715\u001b[0m     sum0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(confusion, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/MCD/LaboII/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:376\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_index_conversion:\n\u001b[1;32m    375\u001b[0m     label_to_ind \u001b[38;5;241m=\u001b[39m {y: x \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels)}\n\u001b[0;32m--> 376\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mlabel_to_ind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y_pred])\n\u001b[1;32m    377\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label_to_ind\u001b[38;5;241m.\u001b[39mget(x, n_labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y_true])\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Inicio el store de artefactos (archivos) de optuna\n",
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "#Genero estudio\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///../work/db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"Final - Ge - LGB Multiclass CV\",\n",
    "                            load_if_exists = True)\n",
    "#Corro la optimizacion\n",
    "run_optuna = True\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "if run_optuna:\n",
    "    study.optimize(cv_es_lgb_objective, n_trials=200, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sorted_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m sorted_trials:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "sorted_trials = sorted(study.get_trials(), key=lambda trial: trial.value, reverse=True)\n",
    "for trial in sorted_trials:\n",
    "    print(f\"Trial {trial.number}: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'lambda_l1': 0.07958720818703245, \n",
    "'lambda_l2': 0.23359973422583905, \n",
    "'num_leaves': 179, \n",
    "'min_data_in_leaf': 28, \n",
    "'feature_fraction': 0.48667927053386195, \n",
    "'bagging_fraction': 0.9896417154375905, \n",
    "'bagging_freq': 5, \n",
    "'min_child_samples': 58, \n",
    "'min_gain_to_split': 0.5653596125981446,\n",
    "'seed': SEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!optuna-dashboard sqlite:///../work/db1.sqlite3 --artifact-dir ../work/optuna_artifacts --port 8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a replicar el resultado de la optimizacion reentrenando el modelo con el mejor conjunto de hiperparametros\n",
    "#Generamos parametros incluyendo los fijos y la mejor solución que encontro optuna\n",
    "lgb_params =  {      **lgbm_params,\n",
    "                        'objective': 'multiclassova',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique())}\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "#Entreno\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                    lgb_train_dataset)\n",
    "\n",
    "lgb_proba = lgb_model.predict(X_val)\n",
    "lgb_pred = lgb_model.predict(X_val).argmax(axis=1)\n",
    "\n",
    "#Muestro matriz de confusion y kappa\n",
    "display(plot_confusion_matrix(y_val, lgb_pred))\n",
    "\n",
    "cohen_kappa_score(y_val,lgb_pred,\n",
    "                  weights = 'quadratic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature': preprocessor.get_feature_names_out(), 'weight': lgb_model.feature_importance(importance_type='gain')})\n",
    "feature_importance.sort_values('weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_proba = load(os.path.join(BASE_DIR, \"resultados_nn_bert/test_04 ResNet_1.0.0_0(2).joblib\"))\n",
    "nn_proba = nn_proba[['PetID', 'pred']]\n",
    "\n",
    "bert_proba = load(os.path.join(BASE_DIR, \"resultados_nn_bert/test_06 Bert_1.0_0.joblib\"))\n",
    "bert_proba = bert_proba[['PetID', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_proba_df = pd.DataFrame({'PetID': X_val_id,\n",
    "                            'lgbm_proba': list(lgb_proba)})\n",
    "\n",
    "all_proba = lgb_proba_df.merge(bert_proba[['PetID', 'pred']].rename({'pred':'bert_proba'},axis=1),\n",
    "                  on='PetID', how='left').merge(nn_proba[['PetID', 'pred']].rename({'pred':'nn_proba'},axis=1),\n",
    "                  on='PetID', how='left').merge(df_train[['PetID','AdoptionSpeed']], on='PetID', how='left')\n",
    "\n",
    "all_proba['bert_proba'] = [np.zeros(5) if type(i) is float else  i for i in all_proba['bert_proba']]\n",
    "all_proba['nn_proba'] = [np.zeros(5) if type(i) is float else  i for i in all_proba['nn_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_proba['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quadratic weighted kappa\n",
    "lgbm_kappa = cohen_kappa_score(y, np.array(all_proba['lgbm_proba'].tolist()).argmax(axis=1), weights='quadratic')\n",
    "# Calculate the quadratic weighted kappa\n",
    "bert_kappa = cohen_kappa_score(y, np.array(all_proba['bert_proba'].tolist()).argmax(axis=1), weights='quadratic')\n",
    "# Calculate the quadratic weighted kappa\n",
    "nn_kappa = cohen_kappa_score(y, np.array(all_proba['nn_proba'].tolist()).argmax(axis=1), weights='quadratic')\n",
    "\n",
    "print(f\"Kappa LGBM: {lgbm_kappa}, Kappa BERT: {bert_kappa}, Kappa NN: {nn_kappa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest weights for each model's predictions\n",
    "    w_lgbm = trial.suggest_float('w_lgbm', 0.5, 1.0)\n",
    "    w_bert = trial.suggest_float('w_bert', 0.0, 0.5)\n",
    "    w_nn = trial.suggest_float('w_nn', 0.0, 0.5)\n",
    "\n",
    "    # Normalize weights\n",
    "    w_sum = w_lgbm + w_bert + w_nn\n",
    "    w_lgbm /= w_sum\n",
    "    w_bert /= w_sum\n",
    "    w_nn /= w_sum\n",
    "\n",
    "    # Calculate the blended predictions\n",
    "    y_pred = np.array((w_lgbm* all_proba['lgbm_proba']+ \n",
    "                        w_bert * all_proba['bert_proba']+\n",
    "                        w_nn* all_proba['nn_proba']).tolist()).argmax(axis=1)\n",
    "    \n",
    "    # Calculate the quadratic weighted kappa\n",
    "    kappa = cohen_kappa_score(y, y_pred, weights='quadratic')\n",
    "\n",
    "    return kappa\n",
    "\n",
    "# Create an Optuna study\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "#optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar = True)\n",
    "\n",
    "# Best weights found\n",
    "best_weights = study.best_trial.params\n",
    "print(\"Best weights:\", best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kappa blend {study.best_value}, \\nKappa LGBM: {lgbm_kappa}, \\nKappa BERT: {bert_kappa}, \\nKappa NN: {nn_kappa}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
