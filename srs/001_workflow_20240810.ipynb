{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import de librerias basicas tablas y matrices\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Funciones auxiliares sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold #Split y cross Validation\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, balanced_accuracy_score #Metricas\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Visualizacióon\n",
    "from plotly import express as px\n",
    "\n",
    "#Plot de matriz de confusion normalizada en actuals\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "#Optimizacion de hiperparametros\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "#Guardado de objetos en archivos joblib\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths para acceso archivos\n",
    "#Este notebook asume la siguiente estructura de carpetas a partir de la ubicacion de base_dir \n",
    "#(dos niveles arriba de la carpeta donde se ejecuta el notebook). \n",
    "# /UA_MDM_LDI_II/\n",
    "# /UA_MDM_LDI_II/input\n",
    "# /UA_MDM_LDI_II/input/petfinder-adoption-prediction/            <- Aca deben ir todos los archivos de datos de la competencia \n",
    "# /UA_MDM_LDI_II/tutoriales/                       <- Aca deben poner los notebooks y scripts que les compartimos\n",
    "# /UA_MDM_LDI_II/work/                             <- Resultados de notebooks iran dentro de esta carpeta en subcarpetas\n",
    "# /UA_MDM_LDI_II/work/models/                     <- Modelos entrenados en archivos joblibs\n",
    "# /UA_MDM_LDI_II/work/optuna_temp_artifacts/      <- Archivos que queremos dejar como artefacto de un trial de optuna (optuna los copiara a la carpeta de abajo)\n",
    "# /UA_MDM_LDI_II/work/optuna_artifacts/           <- Archivos con artefactos que sibimos a optuna\n",
    "\n",
    "#Subimos dos niveles para quedar en la carpeta que contiene input y UA_MDM_LDI_II\n",
    "BASE_DIR = '../'\n",
    "\n",
    "#Datos de entrenamiento \n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_TEST = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/test/test.csv\")\n",
    "\n",
    "#Salida de modelos entrenados\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"work/models\")\n",
    "\n",
    "#Artefactos a subir a optuna\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "\n",
    "#Artefactos que optuna gestiona\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "\n",
    "SEED = 42 #Semilla de procesos aleatorios (para poder replicar exactamente al volver a correr un modelo)\n",
    "TEST_SIZE = 0.2 #Facción para train/test= split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_train = pd.read_csv(PATH_TO_TRAIN)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3972, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos Tabulares\n",
    "df_test = pd.read_csv(PATH_TO_TEST)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "\n",
    "\n",
    "| Variable       | Type         | Description                                                                           |\n",
    "|----------------|--------------|---------------------------------------------------------------------------------------|\n",
    "| `PetID`        | Categorical  | ID (Should be dropped)                                                                |\n",
    "| `AdoptionSpeed`| Categorical  | Target variable                                                                       |\n",
    "| `Type`         | Categorical  | 1 = Cat, 2 = Dog                                                                      |\n",
    "| `Name`         | Categorical  | Name of pet                                                                           |\n",
    "| `Breed1`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Breed2`       | Categorical  | See BreedLabels dictionary                                                            |\n",
    "| `Gender`       | Categorical  | 1 = Male, 2 = Female, 3 = Mixed (used for groups)                                     |\n",
    "| `Color1`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color2`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `Color3`       | Categorical  | See ColorLabels dictionary                                                            |\n",
    "| `MaturitySize` | Categorical  | 1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified                  |\n",
    "| `FurLength`    | Categorical  | 1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified                                    |\n",
    "| `Vaccinated`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Dewormed`     | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Sterilized`   | Categorical  | 1 = Yes, 2 = No, 3 = Not Sure                                                         |\n",
    "| `Health`       | Categorical  | 1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified                  |\n",
    "| `State`        | Categorical  | See StateLabels dictionary                                                            |\n",
    "| `RescuerID`    | Categorical  | ID                                                                                    |\n",
    "| `Description`  | Text         | Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese. |\n",
    "\n",
    "### Quantitative Variables\n",
    "\n",
    "| Variable   | Type             |Description                                           |\n",
    "|------------|------------------|------------------------------------------------------|\n",
    "| `Age`      |  Numerical       |Age of pet when listed, in months                     |\n",
    "| `Quantity` |  Numerical       |Number of pets represented in profile                 |\n",
    "| `Fee`      |  Numerical       |Adoption fee (0 = Free)                               |\n",
    "| `VideoAmt` |  Numerical       |Total uploaded videos for this pet                    |\n",
    "| `PhotoAmt` |  Numerical       |Total uploaded photos for this pet                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_fe(dataset):\n",
    "    # Name\n",
    "    # Feature to know if the pet has a name\n",
    "    unknown_names = 'name|puppies|kitten|puppy|unknown'\n",
    "    dataset['Name'] = np.where(dataset['Name'].str.lower().str.contains(unknown_names), np.nan, dataset['Name'])\n",
    "    dataset['Name'] = np.where(dataset['Name'].str.len() < 3, np.nan, dataset['Name'])\n",
    "    dataset['HasName'] = dataset['Name'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "    \n",
    "    # Breed\n",
    "    # Unify values in Breed1\n",
    "    dataset['Breed1'] = np.where((dataset['Breed1']==0) & (dataset['Breed2']!=0), dataset['Breed2'], dataset['Breed1'])\n",
    "    dataset['Breed2'] = np.where((dataset['Breed1']==dataset['Breed2']), 0, dataset['Breed2'])\n",
    "    \n",
    "    # Merge Breed1 and Breed2\n",
    "    dataset['FullBreed'] = dataset['Breed1'].astype(str) + '_' + dataset['Breed2'].astype(str) \n",
    "    # Pure breed\n",
    "    dataset['PureBreed'] = np.where((dataset['Breed2'] == 0) & (~dataset['Breed1'].isin([307, 266, 265, 264])), 1, 0)\n",
    "    \n",
    "    # Color\n",
    "    # Merge Color1, Color2 and Color3\n",
    "    dataset['Color'] = dataset['Color1'].astype(str) + '_' + dataset['Color2'].astype(str) + '_' + dataset['Color3'].astype(str)\n",
    "    # Monochromatic\n",
    "    dataset['Monochromatic'] = np.where((dataset['Color2'] == 0) & (dataset['Color3'] == 0), 1, 0)\n",
    "    \n",
    "    # Health\n",
    "    # Merge Vaccinated, Dewormed and Sterilized to know if the pet is up to date with routine stuff\n",
    "    dataset['Va_De_St'] = dataset['Vaccinated'].astype(str) + '_' + dataset['Dewormed'].astype(str) + '_' + dataset['Sterilized'].astype(str)\n",
    "\n",
    "    # Code to add a min age for sterilization.... But EDA shows that they do it anyway\n",
    "    #df['CanBeSter'] = np.where((df['Age'] > 9) & (df['Type'] == 1) | (df['Age'] > 6) & (df['Type'] == 2), 1, 0)\n",
    "    \n",
    "    # Fee\n",
    "    # Create fee bins using log transformation\n",
    "    dataset['Fee_bins'] = pd.cut(np.log1p(dataset.Fee), 5, labels=['Fee_{}'.format(e) for e in range(5)])\n",
    "\n",
    "    #RescuerID\n",
    "    rescuer_count = dataset.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "    rescuer_count.columns = ['RescuerID', 'Rescuer_count']\n",
    "    dataset = dataset.merge(rescuer_count, how='left', on='RescuerID')\n",
    "\n",
    "    # Age\n",
    "    dataset['RelAge'] = np.where(dataset['Type'] == 1, dataset['Age']/144, dataset['Age']/180) # Vida media de un gato 12 años, de un perro 15\n",
    "\n",
    "    # Multimedia\n",
    "    dataset['Total_photo_video'] = dataset['PhotoAmt'] + dataset['VideoAmt']\n",
    "\n",
    "    # Si tiene todo lo del veterinatrio en orden\n",
    "    dataset['VetInOrder'] = np.where((dataset['Vaccinated'] == 1) & (dataset['Dewormed'] == 1) & (dataset['Sterilized'] == 1) & (dataset['Health'] == 1), 1, 0)\n",
    "\n",
    "    # Si le falta info sobre lo relacionado a veterinario\n",
    "    dataset['NoVet'] = np.where((dataset['Vaccinated'] == 3) | (dataset['Dewormed'] == 3) | (dataset['Sterilized'] == 3) | (dataset['Health'] == 3), 1, 0)\n",
    "\n",
    "    # Longitud de la descripcion\n",
    "    dataset['LenDesc'] = dataset['Description'].apply(lambda x: len(str(x)))\n",
    "\n",
    "    # State\n",
    "\n",
    "    \n",
    "    # Return the augmented dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = apply_fe(df_train.copy())\n",
    "df_test = apply_fe(df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['AdoptionSpeed']\n",
    "X = df_train.drop(columns=['AdoptionSpeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=SEED, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean adoption speed per state and add that value to train and test datasets\n",
    "state_mean = pd.concat([X_train['State'], y_train], axis=1).groupby('State')['AdoptionSpeed'].mean().reset_index()\n",
    "state_mean.columns = ['State', 'AdoptionSpeed_mean']\n",
    "X_train = X_train.merge(state_mean, how='left', on='State')\n",
    "X_val = X_val.merge(state_mean, how='left', on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
       "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'HasName', 'FullBreed',\n",
       "       'PureBreed', 'Color', 'Monochromatic', 'Va_De_St', 'Fee_bins',\n",
       "       'Rescuer_count', 'RelAge', 'Total_photo_video', 'VetInOrder', 'NoVet',\n",
       "       'LenDesc', 'AdoptionSpeed_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armo listas con features de texto y numericas\n",
    "char_feats = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized','Health', 'State', 'RescuerID',\n",
    "       'Description', 'HasName', 'FullBreed',\n",
    "       'PureBreed', 'Color', 'Monochromatic', 'Va_De_St', 'Fee_bins', 'VetInOrder', 'NoVet','VideoAmt','PhotoAmt','Total_photo_video',\n",
    "       ]\n",
    "\n",
    "numeric_feats = ['Age', 'Quantity', 'Fee', 'RelAge',\n",
    "       'Rescuer_count', 'LenDesc', 'AdoptionSpeed_mean', ]\n",
    "\n",
    "fe_drop = ['Name','PetID',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para revisar que tenemos todas las columnas en las variables\n",
    "X_train.shape[1]-len(fe_drop)-len(char_feats)-len(numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[char_feats + numeric_feats]\n",
    "X_val = X_val[char_feats + numeric_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(min_frequency= 30, handle_unknown= 'use_encoded_value', unknown_value= -1), char_feats)],\n",
    "        remainder= 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 328, number of negative: 11666\n",
      "[LightGBM] [Info] Number of positive: 2472, number of negative: 9522\n",
      "[LightGBM] [Info] Number of positive: 3230, number of negative: 8764\n",
      "[LightGBM] [Info] Number of positive: 2607, number of negative: 9387\n",
      "[LightGBM] [Info] Number of positive: 3357, number of negative: 8637\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 11994, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027347 -> initscore=-3.571420\n",
      "[LightGBM] [Info] Start training from score -3.571420\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206103 -> initscore=-1.348577\n",
      "[LightGBM] [Info] Start training from score -1.348577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.269301 -> initscore=-0.998170\n",
      "[LightGBM] [Info] Start training from score -0.998170\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217359 -> initscore=-1.281126\n",
      "[LightGBM] [Info] Start training from score -1.281126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.279890 -> initscore=-0.945008\n",
      "[LightGBM] [Info] Start training from score -0.945008\n"
     ]
    }
   ],
   "source": [
    "#Entreno un modelo inicial sin modificar hiperparametros. Solamente especifico el numero de clases y el tipo de modelo como clasificacoión\n",
    "lgb_params = params = {\n",
    "                        'objective': 'multiclassova',\n",
    "                        'num_class': 5\n",
    "                        }\n",
    "\n",
    "\n",
    "#genero el objeto Dataset que debo pasarle a lightgbm para que entrene\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "#entreno el modelo con los parametros por defecto\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3327498782523731"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = preprocessor.transform(X_val)\n",
    "\n",
    "y_pred = lgb_model.predict(X_val).argmax(axis=1)\n",
    "\n",
    "#Calculo el Kappa\n",
    "cohen_kappa_score(y_val,y_pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>remainder__LenDesc</td>\n",
       "      <td>12887.932647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>remainder__Rescuer_count</td>\n",
       "      <td>12075.436853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>remainder__RelAge</td>\n",
       "      <td>9339.059376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat__Breed1</td>\n",
       "      <td>5067.221262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cat__PhotoAmt</td>\n",
       "      <td>4940.499122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cat__Color</td>\n",
       "      <td>4545.877137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>remainder__Age</td>\n",
       "      <td>4260.673049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>remainder__AdoptionSpeed_mean</td>\n",
       "      <td>3117.196303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cat__FullBreed</td>\n",
       "      <td>3069.864194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cat__Va_De_St</td>\n",
       "      <td>2957.935708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature        weight\n",
       "33             remainder__LenDesc  12887.932647\n",
       "32       remainder__Rescuer_count  12075.436853\n",
       "31              remainder__RelAge   9339.059376\n",
       "1                     cat__Breed1   5067.221262\n",
       "26                  cat__PhotoAmt   4940.499122\n",
       "19                     cat__Color   4545.877137\n",
       "28                 remainder__Age   4260.673049\n",
       "34  remainder__AdoptionSpeed_mean   3117.196303\n",
       "17                 cat__FullBreed   3069.864194\n",
       "21                  cat__Va_De_St   2957.935708"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'feature': preprocessor.get_feature_names_out(), 'weight': lgb_model.feature_importance(importance_type='gain')})\n",
    "feature_importance.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una metrica para que lightGBM haga la evaluación y pueda hacer early_stopping en el cross validation\n",
    "def lgb_custom_metric_kappa(dy_pred, dy_true):\n",
    "    metric_name = 'kappa'\n",
    "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
    "    is_higher_better = True\n",
    "    return(metric_name, value, is_higher_better)\n",
    "\n",
    "#Funcion objetivo a optimizar. En este caso vamos a hacer 5fold cv sobre el conjunto de train. \n",
    "# El score de CV es el objetivo a optimizar. Ademas vamos a usar los 5 modelos del CV para estimar el conjunto de test,\n",
    "# registraremos en optuna las predicciones, matriz de confusion y el score en test.\n",
    "# CV Score -> Se usa para determinar el rendimiento de los hiperparametros con precision \n",
    "# Test Score -> Nos permite testear que esta todo OK, no use (ni debo usar) esos datos para nada en el entrenamiento \n",
    "# o la optimizacion de hiperparametros\n",
    "\n",
    "def cv_es_lgb_objective(trial):\n",
    "    \n",
    "    y_train_np = np.array(y_train)\n",
    "\n",
    "    #PArametros para LightGBM\n",
    "    lgb_params = {      \n",
    "                        #PArametros fijos\n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        #Hiperparametros a optimizar utilizando suggest_float o suggest_int segun el tipo de dato\n",
    "                        #Se indica el nombre del parametro, valor minimo, valor maximo \n",
    "                        #en elgunos casos el parametro log=True para parametros que requieren buscar en esa escala\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "    #Voy a generar estimaciones de los 5 modelos del CV sobre los datos test y los acumulo en la matriz scores_ensemble\n",
    "    scores_ensemble = np.zeros((len(y_val),len(y_train.unique())))\n",
    "\n",
    "    #Score del 5 fold CV inicializado en 0\n",
    "    score_folds = 0\n",
    "\n",
    "    #Numero de splits del CV\n",
    "    n_splits = 5\n",
    "\n",
    "    #Objeto para hacer el split estratificado de CV\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train_np)):\n",
    "        #Dataset in fold (donde entreno) \n",
    "        lgb_if_dataset = lgb.Dataset(data=X_train[if_index],\n",
    "                                        label=y_train_np[if_index],\n",
    "                                        free_raw_data=False)\n",
    "        \n",
    "        #Dataset Out of fold (donde mido la performance del CV)\n",
    "        lgb_oof_dataset = lgb.Dataset(data=X_train[oof_index],\n",
    "                                        label=y_train_np[oof_index],\n",
    "                                        free_raw_data=False)\n",
    "\n",
    "        #Entreno el modelo\n",
    "        lgb_model = lgb.train(lgb_params,\n",
    "                                lgb_if_dataset,\n",
    "                                valid_sets=lgb_oof_dataset,\n",
    "                                callbacks=[lgb.early_stopping(10, verbose=False)],\n",
    "                                feval = lgb_custom_metric_kappa\n",
    "                                )\n",
    "        \n",
    "        #Acumulo los scores (probabilidades) de cada clase para cada uno de los modelos que determino en los folds\n",
    "        #Se predice el 20% de los datos que separe para tes y no uso para entrenar en ningun fold\n",
    "        scores_ensemble = scores_ensemble + lgb_model.predict(X_val)\n",
    "        \n",
    "        #Score del fold (registros de dataset train que en este fold quedan out of fold)\n",
    "        score_folds = score_folds + cohen_kappa_score(y_train_np[oof_index], \n",
    "                                                            lgb_model.predict(X_train[oof_index]).argmax(axis=1),weights = 'quadratic')/n_splits\n",
    "\n",
    "\n",
    "    #Guardo prediccion del trial sobre el conjunto de test\n",
    "    # Genero nombre de archivo\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    # Copia del dataset para guardar la prediccion\n",
    "    predicted_df = X_val.copy()\n",
    "    # Genero columna pred con predicciones sumadas de los 5 folds\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    # Grabo dataframe en temp_artifacts\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    # Indico a optuna que asocie el archivo generado al trial\n",
    "    upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "    #Grabo natriz de confusion\n",
    "    #Nombre de archivo\n",
    "    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "    #Grabo archivo\n",
    "    plot_confusion_matrix(y_val,scores_ensemble.argmax(axis=1)).write_image(cm_filename)\n",
    "    #Asocio al trial\n",
    "    upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "    #Determino score en conjunto de test y asocio como metrica adicional en optuna\n",
    "    test_score = cohen_kappa_score(y_val,scores_ensemble.argmax(axis=1),weights = 'quadratic')\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    #Devuelvo score del 5fold cv a optuna para que optimice en base a eso\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7282/581466726.py:2: ExperimentalWarning: FileSystemArtifactStore is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "  artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
      "[I 2024-08-20 23:19:25,617] Using an existing study with name '04 - LGB Multiclass CV' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2331  2344  2349 ... 11991 11992 11993]\n",
      "[    0     1     2 ... 11991 11992 11993]\n",
      "[    0     1     2 ... 11991 11992 11993]\n",
      "[    0     1     2 ... 11991 11992 11993]\n",
      "[   0    1    2 ... 9795 9800 9808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-20 23:19:30,208] Trial 18 failed with parameters: {'lambda_l1': 7.627993493604136, 'lambda_l2': 1.2758316154721886e-05, 'num_leaves': 256, 'feature_fraction': 0.5499575604276831, 'bagging_fraction': 0.4314172391972131, 'bagging_freq': 1, 'min_child_samples': 67} because of the following error: IndexError('only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ge/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7282/3813958687.py\", line 84, in cv_es_lgb_objective\n",
      "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
      "    ~~~~~~~~~~~~^^^^^^^^\n",
      "IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "[W 2024-08-20 23:19:30,209] Trial 18 failed with value None.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///../work/db.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Specify the storage URL here.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                             study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m04 - LGB Multiclass CV\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                             load_if_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Corro la optimizacion\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_es_lgb_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/MCD/Laboratorio2/LaboII/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[26], line 84\u001b[0m, in \u001b[0;36mcv_es_lgb_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     82\u001b[0m predicted_df \u001b[38;5;241m=\u001b[39m X_val\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Genero columna pred con predicciones sumadas de los 5 folds\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43mpredicted_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [scores_ensemble[p,:] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(scores_ensemble\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Grabo dataframe en temp_artifacts\u001b[39;00m\n\u001b[1;32m     86\u001b[0m dump(predicted_df, predicted_filename)\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#Inicio el store de artefactos (archivos) de optuna\n",
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "#Genero estudio\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///../work/db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"04 - LGB Multiclass CV\",\n",
    "                            load_if_exists = True)\n",
    "#Corro la optimizacion\n",
    "study.optimize(cv_es_lgb_objective, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
